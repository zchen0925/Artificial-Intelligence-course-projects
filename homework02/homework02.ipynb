{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi Professor Vander Linden, I'm not sure how to configure my local jupyter notebook, and it is only allowing me to use the markdown text format to write down answers. Sorry for the less than ideal formatting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1:\n",
    "The filter is Bayesian because rather than looking for features typical of spam and assigning the message an corresponding score, it uses a probability that is computed from the probability associated with each word in the message. The probability is based on prior evidence -- the frequency the word occurs in both the good and the bad corpus. This is typical of Bayesian probabilities, to use prior probabilities and current evidence to update the understanding. Also, it allows the message \"a chance to be redeemed\" if it has a lot of spam-likely words but also words that appear to be innocent, this is also typical of a Bayesian model that can be updated in both directions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Code implementation of the spam filter and some test cases: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Exercise 1 for CS 344 Homework02, Fall 2019\n",
    "Professor Vander Linden\n",
    "@author: Ziqi Chen\n",
    "@version: Mar 5th, 2019\n",
    "'''\n",
    "import numpy as np\n",
    "debug = 0\n",
    "\n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "\n",
    "class spamFilter():\n",
    "    '''\n",
    "    @param: goodCorpus: input of one or more lists of good emails.\n",
    "    @param: spamCorpus: input of one or more lists of spams.\n",
    "    @attributes: good/badWords: occurrences of words from good/spamCorpus,\n",
    "                ngood/nspam: number of good messages that heed into good/badWords\n",
    "                wordProbs: once a message is fed into the filter, will contain the probability of a word being \"bad\"\n",
    "    '''\n",
    "    def __init__(self, goodCorpus=[], spamCorpus=[]):\n",
    "        self.goodWords = dict()\n",
    "        self.badWords = dict()\n",
    "        self.ngood = 0\n",
    "        self.nspam = 0\n",
    "        self.wordProbs = dict()\n",
    "        for element in goodCorpus:\n",
    "            #check if corpus contains a list of messages\n",
    "            if type(element) is list:\n",
    "                self.ngood += 1\n",
    "                for word in element:\n",
    "                    if type(word) is str:\n",
    "                        word = word.lower()\n",
    "                        try:\n",
    "                            self.goodWords[word] += 1\n",
    "                        except:\n",
    "                            self.goodWords[word] = 1\n",
    "            #if there is only one message\n",
    "            elif type(element) is str:\n",
    "                element = element.lower()\n",
    "                self.ngood += 1\n",
    "                try:\n",
    "                    self.goodWords[element] += 1\n",
    "                except:\n",
    "                    self.goodWords[element] = 1\n",
    "        #same thing creating the spam hash table\n",
    "        for element in spamCorpus:\n",
    "            # check if corpus contains a list of messages\n",
    "            if type(element) is list:\n",
    "                self.nspam += 1\n",
    "                for word in element:\n",
    "                    if type(word) is str:\n",
    "                        word = word.lower()\n",
    "                        try:\n",
    "                            self.badWords[word] += 1\n",
    "                        except:\n",
    "                            self.badWords[word] = 1\n",
    "            # if there is only one message\n",
    "            elif type(element) is str:\n",
    "                element = element.lower()\n",
    "                self.nspam += 1\n",
    "                try:\n",
    "                    self.badWords[element] += 1\n",
    "                except:\n",
    "                    self.badWords[element] = 1\n",
    "\n",
    "\n",
    "    '''\n",
    "    @param: msg is a list of individual words that have been scanned and separated    \n",
    "    @result: update self.wordProbs with the probability that each word in msg is associated with spam.\n",
    "    '''\n",
    "    def listProbs(self, msg):\n",
    "        for word in msg:\n",
    "            word = word.lower()\n",
    "            #algorithm taken from Paul Graham's 'A Plan for Spam' (http://www.paulgraham.com/spam.html)\n",
    "            try:\n",
    "                g = 2 * self.goodWords[word]\n",
    "            except:\n",
    "                g = 0\n",
    "            try:\n",
    "                b = self.badWords[word]\n",
    "            except:\n",
    "                b = 0\n",
    "            if (g + b) > 1:\n",
    "                spam = max(0.01, min(0.99, (min(1, b/self.nspam) / (min(1, g/self.ngood) + min(1, b/self.nspam)))))\n",
    "                self.wordProbs[word] = spam\n",
    "            # if word does not occur in the hash tables, assign it probability value 0.4 (as suggested by the author)\n",
    "            else:\n",
    "                self.wordProbs[word] = 0.4\n",
    "\n",
    "    '''\n",
    "    @param: msg is a list of pre-scanned tokens\n",
    "    @return: based on the 15 most interesting probabilities of words in msg, calculate a overall probability that the message is spam\n",
    "    '''\n",
    "    def spamProb(self, msg):\n",
    "        msgProbs = []\n",
    "        for word in msg:\n",
    "            if word in self.wordProbs:\n",
    "                msgProbs.append(self.wordProbs[word])\n",
    "        if len(msgProbs) > 15:\n",
    "            msgProbs = [abs(x - 0.5) for x in msgProbs]\n",
    "            msgProbs = sorted(msgProbs)[:15]\n",
    "        prod = np.product(msgProbs)\n",
    "        prod1 = np.product([1 - x for x in msgProbs])\n",
    "        combined = prod / (prod + prod1)\n",
    "        return combined\n",
    "\n",
    "    '''\n",
    "    @param: msg: list of tokens\n",
    "    @param: list: a boolean manipulator on whether to print probability of individual words\n",
    "    @result: print spam probability of this msg and individual word spam probabilities\n",
    "    '''\n",
    "    def spamResult(self, msg, list = 1):\n",
    "        self.listProbs(msg)\n",
    "        print(\"Spam probability: \", str(round(self.spamProb(msg), 3)))\n",
    "        if list:\n",
    "            print('{:15s}{:15s}'.format(\"Word:\",\"Probability:\"))\n",
    "            for word in msg:\n",
    "                word = word.lower()\n",
    "                if word in self.wordProbs:\n",
    "                    prob = self.wordProbs[word]\n",
    "                    print('{:15s}{:15s}'.format(word, str(round(prob, 3))))\n",
    "\n",
    "\n",
    "    '''\n",
    "    @type: good or spam\n",
    "    @msgs: a list of msgs, which each is a list of tokens\n",
    "    @result: update the filter's goodWords or badWords dicts and ngood or nspam\n",
    "    '''\n",
    "    def updateFilter(self, type, msgs):\n",
    "        type = type.lower()\n",
    "        if type == \"good\":\n",
    "            for msg in msgs:\n",
    "                self.ngood += 1\n",
    "                for word in msg:\n",
    "                    if type(word) is str:\n",
    "                        word = word.lower()\n",
    "                        try:\n",
    "                            self.goodWords[word] += 1\n",
    "                        except:\n",
    "                            self.goodWords[word] = 1\n",
    "        elif type == \"spam\":\n",
    "            for msg in msgs:\n",
    "                self.nspam += 1\n",
    "                for word in msg:\n",
    "                    if type(word) is str:\n",
    "                        word = word.lower()\n",
    "                        try:\n",
    "                            self.badWords[word] += 1\n",
    "                        except:\n",
    "                            self.badWords[word] = 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    simpleFilter = spamFilter(ham_corpus, spam_corpus)\n",
    "    if debug:\n",
    "        print(simpleFilter.ngood, simpleFilter.nspam, simpleFilter.goodWords, simpleFilter.badWords)\n",
    "    msgs = [ham_corpus[0], ham_corpus[1], spam_corpus[0], spam_corpus[1]]\n",
    "    for msg in msgs:\n",
    "        print(\"\\n\", msg)\n",
    "        #print the spam message probability for each list in the spam and ham\n",
    "        simpleFilter.spamResult(msg,0)\n",
    "\n",
    "    print(\"Get dict of word probabilities: \\n\", simpleFilter.wordProbs)\n",
    "    test0 = [\"self\", \"i\", \"spam\",\"am\", \"do\", \"eggs\", \"piglet\", \"green\"]\n",
    "    test1 = [\"this\", \"is\", \"spam\", \"spam\", \"am\"]\n",
    "    test2 = [\"would\", \"you\", \"like\", \"some\", \"green\", \"eggs\", \"and\", \"ham\", \"?\"]\n",
    "    simpleFilter.spamResult(test0)\n",
    "    simpleFilter.spamResult(test1)\n",
    "    simpleFilter.spamResult(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2."
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 6,
   "source": [
    "There are 15 independent values in the full joint probability distribution, if the understanding that this is also the degree of freedom is correct, since there are 4 variables, there will be 16 entries, and 15 of those will be able to take on any values between 0 and 1, but the last one must add up to one with the previous entries.\n",
    "\n",
    "If I'm understanding correctly, there are 8 independent values in the Bayesian network, because there are a total of 9 probabilities, and one of them is restricted.\n",
    "\n",
    "Submitted hand-written solutions to your office."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nCode that computes the following probabilities: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Exercise 2 for CS 344 Homework02, Fall 2019\n",
    "Professor Vander Linden\n",
    "@author: Ziqi Chen\n",
    "@version: Mar 5th, 2019\n",
    "'''\n",
    "\n",
    "from probability import BayesNet, enumeration_ask, elimination_ask, gibbs_ask\n",
    "\n",
    "# Utility variables\n",
    "T, F = True, False\n",
    "\n",
    "cloudy = BayesNet([('Cloudy', '', 0.5),\n",
    "                   ('Sprinkler', 'Cloudy', {T: 0.10, F: 0.50}),\n",
    "                   ('Rain', 'Cloudy', {T: 0.80, F: 0.20}),\n",
    "                   ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F):0.90, (F, T): 0.90, (F, F): 0.00})\n",
    "                   ])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "d.i \n",
    "P(Cloudy) = <0.5, 0.5>\n",
    "\"\"\"\n",
    "print(\"P(Cloudy): \", enumeration_ask('Cloudy', dict(), cloudy).show_approx())\n",
    "\n",
    "\"\"\"\n",
    "d.ii\n",
    "    P(Sprinkler | cloudy)\n",
    "=   <0.10, 0.90>\n",
    "\"\"\"\n",
    "print(\"P(Sprinkler | cloudy): \", enumeration_ask('Sprinkler', dict(Cloudy = T), cloudy).show_approx())\n",
    "\n",
    "\"\"\"\n",
    "d.iii\n",
    "    P(Cloudy | the sprinkler is running and it's not raining)\n",
    "=   P(Cloudy | sprinker ^ -rain)\n",
    "=   alpha * P(sprinkler ^ -rain | Cloudy) * P(Cloudy)\n",
    "=   alpha * <0.02 * 0.5, 0.40 * 0.50>\n",
    "=   <0.0476, 0.9524>\n",
    "\"\"\"\n",
    "print(\"P(Cloudy | sprinkler ^ -rain): \", enumeration_ask('Cloudy', dict(Sprinkler = T, Rain = F), cloudy).show_approx())\n",
    "\n",
    "\"\"\"\n",
    "d.iv\n",
    "    P(WetGrass | it's cloudy, the sprinkler is running and it's raining)\n",
    "=   P(WetGrass | cloudy ^ sprinkler ^ rain)\n",
    "=   P(WG | sprinkler ^ rain) * P(sprinkler ^ rain | cloudy) * P(cloudy)\n",
    "=   <0.99, 0.01>\n",
    "\"\"\"\n",
    "print(\"P(WetGrass | cloudy, sprinkler, rain): \", enumeration_ask('WetGrass', dict(Cloudy = T, Sprinkler = T, Rain = T), cloudy).show_approx())\n",
    "\n",
    "\"\"\"\n",
    "d.v\n",
    "    P(Cloudy | grass is not wet)\n",
    "=   P(- wetgrass | Sprinkler, Rain) * P(Sprinkler, Rain | Cloudy) * P(Cloudy)\n",
    "=   alpha * P(-wetgrass | Sprinkler, Rain) * P(Sprinkler, Rain | Cloudy)\n",
    "=   alpha * <(0.01 * 0.08 + 0.10 * (0.02 + 0.72) + 1 * 0.18,  (0.01 * 0.10 + 0.10 * (0.40 + 0.10) + 1 * 0.40)>\n",
    "=   alpha * <0.2548, 0.451>\n",
    "=   <0.361, 0.639>\n",
    "\"\"\"\n",
    "print(\"P(Cloudy | -wetgrass): \", enumeration_ask('Cloudy', dict(WetGrass = F), cloudy).show_approx())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
