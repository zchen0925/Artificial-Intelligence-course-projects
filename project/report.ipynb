{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "\u003ch4\u003e\u003ccenter\u003e AI Project Proposal Draft 2 \u003c/h4\u003e\n\u003ch5\u003eZiqi Chen\u003cbr\u003e\nCS 344\u003cbr\u003e\nMay 3rd, 2019\u003c/h5\u003e\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\u003ch5\u003eVision — Give an overview of the project and its purpose.\u003c/h5\u003e\nThis project was inspired from the neuroscience principle that our visual cortex is a complex system that designates specialized area or group of areas for the processing of different types of visual stimuli. Based on this idea, the activation patterns in our brains should be unique when we are seeing different classes of visual stimuli, such as a human face versus a cat versus an inanimate object.  \nWith the recent advance of neuroimaging technologies, we have more tools to shed light upon how our brain works. The brain scan data is piling up, but it isn\u0027t always easy for humans to pick apart the patterns and connections hidden in the fMRI images right away.  \nIn this project, I am interested to learn how to apply the strengths of Machine-Learning models we\u0027ve learned about in class: pattern-extraction, to simple analysis of neuroimagine data. This project trains ML models on a classification task, one that uses a form of represented fMRI data to find hidden distinct brain activation patterns that result from seeing a class of visual stimuli, and predicts the type of stimuli the person was seeing when this brain activity was recorded. \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\u003ch5\u003eBackground\u003c/h5\u003e\nThis project aims to do a multiclass (3) classification of brain imaging samples. I\u0027m using the [Haxby et al (2001) dataset](https://zenodo.org/record/1203329#.XNpTO0MpBqs) to perform a 3-way classification, trying to train the models to distinguish the fMRI brain scans that result from seeing a face, a cat, or a house. The dataset contains block-design fMRI data for 6 subjects who viewed 12 runs of repeated visual presentations of various stimuli. For the purpose of this project, only subjects 1 - 4 were included as they have complete fMRI data and the corresponding text labels, describing the stimuli type used in each trial. \nIn terms of fMRI data manipulation, This project relies on NiLearn, a Python Scikit-Learn based library with high-level functions for manipulation and analysis of neuroimaging data. In particular, I reference the [documentation on the NiftiMasker class](http://nilearn.github.io/modules/generated/nilearn.input_data.NiftiMasker.html) which does the heavy-lifting of readying the fMRI data to be used by models. It applies a mask to 4D fMRI images to extract 2D arrays, with each datapoint representing voxel of brain region activation * time. In loadingData.py, I cited [this NiLearn example](http://nilearn.github.io/auto_examples/plot_decoding_tutorial.html#sphx-glr-auto-examples-plot-decoding-tutorial-py) to create a data matrix from the fMRIs.\nIn terms of technologies used, I experimented with a simple [DNN](https://github.com/kvlinden-courses/cs344-code/blob/master/u08features/keras-mnist.ipynb) and [CNN](https://github.com/kvlinden-courses/cs344-code/blob/master/u09classification/keras-cnn.ipynb) models. Neural networks, especially Convolutional Neural Networks, are known for image-processing and classification, hence the inclusion in this project.  \nLast but not least, I used Linear Support Vector Machines as one of the models. Support Vector Machines are a class of supervised machine learning methods for classification and regression tasks. SVMs represent the training data as points in space (cited from [https://en.wikipedia.org/wiki/Support-vector_machine], and use a subset of training points in the decision function, also called support vectors. Its basic philosophy is to find the hyper-plane that most efficiently separates each class of samples from each other (cited from [https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/].  \nFrom talking with Professor Vander Linden during the walkthrough, I learned that Support Vector Machines have been studied for a couple decades, and they have strong support for smaller datasets. Considering the size of this dataset, SVMs seem a good choice. Additionally, Support Vector Classification is known for its strength in classification problems that have high dimensional X inputs (cited from [https://scikit-learn.org/stable/modules/svm.html]), and that is the case in this project. It is effective not only in binary classification, but also multiclass classification problems. For the latter, SVMs supports two types of approaches: one-vs-rest or one-vs-one. One-vs-rest establishes one class and compares it against the other, whereas one-vs-one compares every class with every other, hence more computationally demanding (cited from [https://stats.stackexchange.com/questions/142325/svm-three-way-classification]. This project uses the former approach, one-vs-rest. The implementation of this model is based on [https://scikit-learn.org/stable/modules/svm.html#multi-class-classification].  \nThe fine-tuning of SVM hyperparameters came from documentation on the set__params method from [this page](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\u003ch5\u003eImplementation — Summarize your implementation and, if appropriate, how it extends on the work you’ve referenced\u003c/h5\u003e\nGiven NiLearn\u0027s high-level pre-built functions, some of the implementation details will be carried out automatically in \nthe library.\nAfter reading tutorials, I think that the first step in implementation is downloading the dataset which will then be loaded\ninto Python. Next, I\u0027ll use NiLearn functions transforming 3D images with a time series into 2D arrays that Scikit accepts.\nThen a Support Vector Machine estimator will be trained on the data for the first two tasks. The parameters will be tweaked\nto achieve a satisfiable accuracy. Then, I\u0027ll need to research NiLearn functions that will plot the resulting brain activities\nfrom the prediction result arrays. Finally, for the third task, a correlation matrix need to be created based on time series data.\nA GraphicLasso estimator will be fit on the correlation matrix. I will look for existing projects on functional connectivity maps\nand compare the model\u0027s prediction with their findings. ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\u003ch5\u003eResults — Give the results of your system and comparing them with other similar work\u003c/h5\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Loading and Preprocessing of data**  \nHere I first download the Haxby dataset and then use the NiftiMasker class from NiLearn to preprocess the 4D fMRI images into numpy matrices. ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": "# loadingData.py employs the NiLearn Python library to download the Haxby dataset,\n# which contains the brain scan images of four subjects and the accompanying labels\n# of the images they looked at while their brain activity was captured.\n# NiftiMasker function in the NiLearn library was used to transform the 4D brain scan images into 2D Numpy arrays,\n# which are vectors in which each datapoint represents the extrapolated brain tissue voxel * time\n\nfrom nilearn import datasets, image, plotting\nfrom nilearn.input_data import NiftiMasker\nfrom nilearn.image.image import mean_img\nfrom nilearn.image import index_img\nimport numpy as np\nimport pandas as pd\n\n#import Haxby et al.(2001): Faces and Objects in Ventral Temporal Cortex (fMRI)\n# Subjects 5 and 6 don\u0027t have complete label or anatomical information, only included subjects 1-4\nhaxby_dataset \u003d datasets.fetch_haxby(subjects\u003d4)\n\n#load nifti images for the given subjects. Range 0-3\n#defaults to subject 2\ndef loadSubject(subjectNum \u003d 1):\n    # \u0027func\u0027 is a list of filenames: one for each subject\n    fmri_filename \u003d haxby_dataset.func[subjectNum]\n    return fmri_filename\n\nfmri_filename \u003d loadSubject(0)\nbehavioral \u003d pd.read_csv(haxby_dataset.session_target[0], sep\u003d\" \")\nconditions \u003d behavioral[\u0027labels\u0027]\n\nfacecat_mask \u003d conditions.isin([\u0027face\u0027, \u0027cat\u0027])\nconditions_facecat \u003d conditions[facecat_mask]\nsession_facecat \u003d behavioral[facecat_mask].to_records(index \u003d False)\n\nfacehouse_mask \u003d conditions.isin([\u0027face\u0027, \u0027house\u0027])\nconditions_facehouse \u003d conditions[facehouse_mask]\nsession_facehouse \u003d behavioral[facehouse_mask].to_records(index \u003d False)\n\nthreeway_mask \u003d conditions.isin([\u0027face\u0027, \u0027house\u0027, \u0027cat\u0027])\nconditions_threeway \u003d conditions[threeway_mask]\nsession_threeway \u003d behavioral[threeway_mask].to_records(index \u003d False)\nmask_filename \u003d haxby_dataset.mask\n\n#masking the data from 4D image to 2D array: voxel x time\n#with smothing and standardization\nmasker \u003d NiftiMasker(mask_img\u003dmask_filename, smoothing_fwhm\u003d4, standardize\u003dTrue, memory\u003d\"nilearn_cache\", memory_level\u003d1)\nX \u003d masker.fit_transform(fmri_filename)\n\n# Apply our condition_mask to subject 1\u0027s brain scans:\nFC \u003d X[facecat_mask]\nFH \u003d X[facehouse_mask]\nFHC \u003d X[threeway_mask]\n\n# References\n# Haxby, J., Gobbini, M., Furey, M., Ishai, A., Schouten, J., and Pietrini, P. (2001). Distributed and overlapping representations of faces and objects in ventral temporal cortex. Science 293, 2425-2430.\n\ndef processSubject(sub):\n    mask_filename \u003d haxby_dataset.mask\n    # masking the data from 4D image to 2D array: voxel x time\n    # with smothing and standardization\n    masker \u003d NiftiMasker(mask_img\u003dmask_filename, smoothing_fwhm\u003d4, standardize\u003dTrue, memory\u003d\"nilearn_cache\",\n                         memory_level\u003d1)\n    X \u003d masker.fit_transform(loadSubject(sub))\n    behavioral \u003d pd.read_csv(haxby_dataset.session_target[sub], sep\u003d\" \")\n    conditions \u003d behavioral[\u0027labels\u0027]\n    threeway_mask \u003d conditions.isin([\u0027face\u0027, \u0027house\u0027, \u0027cat\u0027])\n    conditions_threeway \u003d conditions[threeway_mask]\n    FHC \u003d X[threeway_mask]\n    return FHC, conditions_threeway\n\ndef processSessions(sub):\n    behavioral \u003d pd.read_csv(haxby_dataset.session_target[sub], sep\u003d\" \")\n    conditions \u003d behavioral[\u0027labels\u0027]\n    threeway_mask \u003d conditions.isin([\u0027face\u0027, \u0027house\u0027, \u0027cat\u0027])\n    session_threeway \u003d behavioral[threeway_mask].to_records(index \u003d False)\n    return session_threeway\n\nX_all, Y_all \u003d processSubject(0)\nsession_all \u003d  processSessions(0)\nfor sub in range(1, 4):\n    x, y \u003d processSubject(sub)\n    session \u003d processSessions(sub)\n    X_all \u003d np.concatenate((X_all, x), axis \u003d 0)\n    Y_all \u003d np.concatenate((Y_all, y))\n    session_all \u003d np.concatenate((session_all, session))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Shape of concatenated transformed fMRI data:",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "data": {
            "text/plain": "(1296, 39912)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 5
        }
      ],
      "source": "X_all.shape",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Example row in the resulting 2D array: ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "data": {
            "text/plain": "array([-1.121251  , -1.1173762 , -1.0611467 , ...,  0.84500587,\n        0.89118195,  0.96187204], dtype\u003dfloat32)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 6
        }
      ],
      "source": "X_all[0]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Shape of concatenated sessions:  ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "data": {
            "text/plain": "(1296,)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 8
        }
      ],
      "source": "session_all.shape",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "First fifteen tuples recording sessions: ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "data": {
            "text/plain": "array([(\u0027face\u0027, 0), (\u0027face\u0027, 0), (\u0027face\u0027, 0), (\u0027face\u0027, 0), (\u0027face\u0027, 0),\n       (\u0027face\u0027, 0), (\u0027face\u0027, 0), (\u0027face\u0027, 0), (\u0027face\u0027, 0), (\u0027cat\u0027, 0),\n       (\u0027cat\u0027, 0), (\u0027cat\u0027, 0), (\u0027cat\u0027, 0), (\u0027cat\u0027, 0), (\u0027cat\u0027, 0)],\n      dtype\u003d(numpy.record, [(\u0027labels\u0027, \u0027O\u0027), (\u0027chunks\u0027, \u0027\u003ci8\u0027)]))"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 9
        }
      ],
      "source": "session_all[0:15]\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Three-way classification with simple Dense Neural Net**  \nHere I use a simple neural network on the processed 2D dataset. This is a different type of ML model than the example SVM in the binary classification tutorial. ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\ndense_1 (Dense)              (None, 32)                1277216   \n_________________________________________________________________\ndense_2 (Dense)              (None, 16)                528       \n_________________________________________________________________\ndense_3 (Dense)              (None, 3)                 51        \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nTotal params: 1,277,795\nTrainable params: 1,277,795\nNon-trainable params: 0\n_________________________________________________________________\n",
            "Epoch 1/10\n",
            "\r324/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 1s - loss: 1.3288 - acc: 0.3272",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r648/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 3.5050 - acc: 0.3627",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r800/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 2ms/step - loss: 3.8020 - acc: 0.3650\n",
            "Epoch 2/10\n",
            "\r324/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 4.2186 - acc: 0.4630",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r648/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 3.8586 - acc: 0.4954",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b",
            "\r800/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 841us/step - loss: 3.8493 - acc: 0.4963\n",
            "Epoch 3/10\n",
            "\r324/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 3.1185 - acc: 0.5833",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r648/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 2.8445 - acc: 0.6157",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r800/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 895us/step - loss: 2.8193 - acc: 0.6212\n",
            "Epoch 4/10\n",
            "\r324/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 2.5199 - acc: 0.6698",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r648/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 2.3658 - acc: 0.7130",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r800/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 905us/step - loss: 2.2956 - acc: 0.7237\n",
            "Epoch 5/10\n",
            "\r324/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 2.1564 - acc: 0.7593",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r648/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 2.0064 - acc: 0.7809",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r800/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 899us/step - loss: 1.9380 - acc: 0.7925\n",
            "Epoch 6/10\n",
            "\r324/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 1.8729 - acc: 0.8210",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r648/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 1.6844 - acc: 0.8380",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r800/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 766us/step - loss: 1.7012 - acc: 0.8412\n",
            "Epoch 7/10\n",
            "\r324/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 1.9027 - acc: 0.8488",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r648/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 1.6132 - acc: 0.8735",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r800/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 797us/step - loss: 1.5681 - acc: 0.8687\n",
            "Epoch 8/10\n",
            "\r324/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 1.2811 - acc: 0.9043",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r648/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 1.4035 - acc: 0.8981",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r800/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 925us/step - loss: 1.4576 - acc: 0.8950\n",
            "Epoch 9/10\n",
            "\r324/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 1.3999 - acc: 0.9012",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r648/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 1.3017 - acc: 0.9090",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r800/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 809us/step - loss: 1.3273 - acc: 0.9088\n",
            "Epoch 10/10\n",
            "\r324/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 1.1367 - acc: 0.9228",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r648/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 1.2539 - acc: 0.9182",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r800/800 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 784us/step - loss: 1.3022 - acc: 0.9163\n",
            "\r 32/496 [\u003e.............................] - ETA: 1s",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/496 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 0s",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r224/496 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r352/496 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r448/496 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r496/496 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s 749us/step\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "import numpy as np\nfrom keras import models\nfrom keras.layers import Dense\nfrom sklearn.preprocessing import OneHotEncoder\n\n#three-way classification with NN\nX_train \u003d X_all[:800]\nX_val \u003d X_all[800:]\n\n#need to one-hot encode the Y labels\nenc \u003d OneHotEncoder()\n#cited from https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\nY \u003d enc.fit_transform(Y_all[:, np.newaxis]).toarray()\nY_train \u003d Y[:800]\nY_val \u003d Y[800:]\n\n#DNN on all 4 subjects (1294 trials)\nmodel \u003d models.Sequential()\nmodel.add(Dense(32, input_dim \u003d 39912, activation\u003d\u0027relu\u0027))\nmodel.add(Dense(16, input_dim \u003d 32, activation\u003d\u0027relu\u0027))\nmodel.add(Dense(3, activation\u003d\u0027softmax\u0027))\nmodel.summary()\n\nmodel.compile(optimizer\u003d\u0027adam\u0027, loss\u003d\u0027categorical_crossentropy\u0027, metrics\u003d[\u0027accuracy\u0027])\nmodel.fit(X_train, Y_train, batch_size\u003d324, epochs\u003d10, verbose\u003d1)\nscore \u003d model.evaluate(X_val, Y_val)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Model with all four subjects data\nTest loss \u0026 Test accuracy: ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "data": {
            "text/plain": "5.149821404487856"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 11
        }
      ],
      "source": "score[0]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [
        {
          "data": {
            "text/plain": "0.40524193548387094"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 27
        }
      ],
      "source": "score[1]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Three-way classification with Convolutional Neural Network**  \nAgain, CNN are a different class of model specializing in image classification. Here I use a form of the original brain scans instead of the masker-transformed voxel time series. ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "length of all trials:  1452\n",
            "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nconv2d_13 (Conv2D)           (None, 38, 62, 32)        18464     \n_________________________________________________________________\nmax_pooling2d_9 (MaxPooling2 (None, 19, 31, 32)        0         \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 17, 29, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_10 (MaxPooling (None, 8, 14, 64)         0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 6, 12, 64)         36928     \n_________________________________________________________________\nflatten_5 (Flatten)          (None, 4608)              0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 64)                294976    \n_________________________________________________________________\ndense_13 (Dense)             (None, 3)                 195       \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nTotal params: 369,059\nTrainable params: 369,059\nNon-trainable params: 0\n_________________________________________________________________\n",
            "Epoch 1/7\n",
            "\r100/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 3s - loss: 11.9274 - acc: 0.2600",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 1s - loss: 11.1215 - acc: 0.3100",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r250/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 6s 23ms/step - loss: 10.8958 - acc: 0.3240\n",
            "Epoch 2/7\n",
            "\r100/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 3s - loss: 11.7662 - acc: 0.2700",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 1s - loss: 11.4438 - acc: 0.2900",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r250/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 6s 22ms/step - loss: 10.8958 - acc: 0.3240\n",
            "Epoch 3/7\n",
            "\r100/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 3s - loss: 10.7991 - acc: 0.3300",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 1s - loss: 10.7991 - acc: 0.3300",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r250/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 5s 22ms/step - loss: 10.8958 - acc: 0.3240\n",
            "Epoch 4/7\n",
            "\r100/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 3s - loss: 10.3156 - acc: 0.3600",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 1s - loss: 10.3962 - acc: 0.3550",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r250/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 5s 22ms/step - loss: 10.8958 - acc: 0.3240\n",
            "Epoch 5/7\n",
            "\r100/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 3s - loss: 11.2827 - acc: 0.3000",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 1s - loss: 10.9603 - acc: 0.3200",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r250/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 26ms/step - loss: 10.8958 - acc: 0.3240\n",
            "Epoch 6/7\n",
            "\r100/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 3s - loss: 10.7991 - acc: 0.3300",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 1s - loss: 11.2827 - acc: 0.3000",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r250/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 5s 21ms/step - loss: 10.8958 - acc: 0.3240\n",
            "Epoch 7/7\n",
            "\r100/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 3s - loss: 10.9603 - acc: 0.3200",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 1s - loss: 11.0409 - acc: 0.3150",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r250/250 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 6s 24ms/step - loss: 10.8958 - acc: 0.3240\n",
            "\r32/74 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r64/74 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r74/74 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 16ms/step\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "from keras import layers, models\nfrom nilearn.image import crop_img, index_img, iter_img\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\n\ndef loadFilteredImages(sub):\n    behavioral \u003d pd.read_csv(haxby_dataset.session_target[sub], sep\u003d\" \")\n    conditions \u003d behavioral[\u0027labels\u0027]\n    print(\"length of all trials: \", len(conditions))\n    threeway_mask \u003d conditions.isin([\u0027face\u0027, \u0027house\u0027, \u0027cat\u0027])\n    images \u003d index_img(loadSubject(sub), threeway_mask)\n    return images\n\n#for subject 1, returned images are a set of 324 frames/trials, each containing 40 slices of 64*64 images\n#original shape: (40, 64, 64, 324)\nsubj1_images \u003d loadFilteredImages(0)\nimages \u003d np.empty((40, 64, 64))\n#use np.stack to reshape the 4D image array to (324, 40, 64, 64)\nimages \u003d np.stack([img.dataobj for i, img in enumerate(iter_img(subj1_images))])\ntrain_images \u003d images[:250]\nval_images \u003d images[250:]\n#need to one-hot encode the Y labels\nenc \u003d OneHotEncoder()\n#cited from https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\nY \u003d enc.fit_transform(conditions_threeway[:, np.newaxis]).toarray()\nY_train \u003d Y[:250]\nY_val \u003d Y[250:]\n\n#cited from https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.1-introduction-to-convnets.ipynb\nmodel \u003d models.Sequential()\nmodel.add(layers.Conv2D(32, kernel_size \u003d (3, 3), activation\u003d\u0027relu\u0027, input_shape\u003d(40, 64, 64)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation\u003d\u0027relu\u0027))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation\u003d\u0027relu\u0027))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation\u003d\u0027relu\u0027))\nmodel.add(layers.Dense(3, activation\u003d\u0027softmax\u0027))\nmodel.summary()\n\nmodel.compile(optimizer\u003d\u0027rmsprop\u0027,\n              loss\u003d\u0027categorical_crossentropy\u0027,\n              metrics\u003d[\u0027accuracy\u0027])\nmodel.fit(train_images, Y_train, epochs\u003d7, batch_size\u003d100)\n\ntest_loss, test_acc \u003d model.evaluate(val_images, Y_val)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Test loss \u0026 test accuracy: ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "outputs": [
        {
          "data": {
            "text/plain": "10.237168692253732"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 30
        }
      ],
      "source": "test_loss",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [
        {
          "data": {
            "text/plain": "0.3648648616429922"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 31
        }
      ],
      "source": "test_acc",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Three-way classification on Subject 1 with SVM**  \nThis module extends upon the tutorial I followed by doing three-way instead of binary classification. ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "source": "from sklearn.feature_selection import SelectPercentile, f_classif, chi2, SelectKBest\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import LeaveOneGroupOut, cross_val_score\nimport matplotlib.pyplot as plt\n\n#cited from: https://nilearn.github.io/auto_examples/02_decoding/plot_haxby_anova_svm.html\n    # Define the dimension reduction to be used.\n    # Here we use a classical univariate feature selection based on F-test,\n    # namely Anova. When doing full-brain analysis, it is better to use\n    # SelectPercentile, keeping 5% of voxels\n    # (because it is independent of the resolution of the data).\nfeature_selection \u003d SelectPercentile(f_classif, percentile\u003d5)\nk_features \u003d SelectKBest(f_classif, k \u003d 7)\n\n# Output accuracy\n# Define the cross-validation scheme used for validation.\n# Here we use a LeaveOneGroupOut cross-validation on the session group\n# which corresponds to a leave-one-session-out\ndef modelAccuracy(model, X, conditions, groups):\n    cv \u003d LeaveOneGroupOut()\n    # Compute the prediction accuracy for the different folds (i.e. session)\n    cv_scores \u003d cross_val_score(model, X, conditions, cv\u003dcv, groups\u003dgroups)\n    # Return the corresponding mean prediction accuracy\n    classification_accuracy \u003d cv_scores.mean()\n    # Print the results\n    print(\"Classification accuracy: %.4f / Chance level: %f\" %\n          (classification_accuracy, 1. / 3))\n\n#one-vs-the-rest linear kernel\n#cited from https://scikit-learn.org/stable/modules/svm.html#multi-class-classification\n#Pipeline ANOVA SVM with anova F-value, percetile feature selection. This is univariate feature selection",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Fitting a linear SVC with Pipelined Anova f-value feature selection on subject 1 (324) trials: ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "data": {
            "text/plain": "Pipeline(memory\u003dNone,\n     steps\u003d[(\u0027anova\u0027, SelectPercentile(percentile\u003d3.3,\n         score_func\u003d\u003cfunction f_classif at 0x000001F09A925620\u003e)), (\u0027svc\u0027, LinearSVC(C\u003d10, class_weight\u003dNone, dual\u003dTrue, fit_intercept\u003dTrue,\n     intercept_scaling\u003d1, loss\u003d\u0027squared_hinge\u0027, max_iter\u003d750,\n     multi_class\u003d\u0027ovr\u0027, penalty\u003d\u0027l2\u0027, random_state\u003dNone, tol\u003d0.0001,\n     verbose\u003d0))])"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 18
        }
      ],
      "source": "lin_svc \u003d LinearSVC()\nfacecathouse_svc \u003d Pipeline([(\u0027anova\u0027, feature_selection), (\u0027svc\u0027, lin_svc)])\nfacecathouse_svc.set_params(svc__C \u003d 10, svc__max_iter \u003d 2500)\nfacecathouse_svc.set_params(anova__percentile \u003d 3.3, svc__max_iter \u003d 750)\nfacecathouse_svc.fit(FHC, conditions_threeway)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Pipelined SVM with linear kernel accuracy:",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Classification accuracy: 0.6605 / Chance level: 0.333333\n"
          ],
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs\u003d1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs\u003d1)]: Done   6 out of   6 | elapsed:    3.2s finished\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "modelAccuracy(facecathouse_svc, FHC, conditions_threeway, session_threeway)\ncross_validation \u003d cross_val_score(facecathouse_svc, FHC, conditions_threeway, cv \u003d 6, verbose \u003d 1)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Pipelined SVM with linear kernel cross validation score: ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [
        {
          "data": {
            "text/plain": "0.7499999999999999"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 21
        }
      ],
      "source": "cross_validation.mean()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Three-way classification with SVM on all four subjects**  \nThis module extends upon previous work by including all four subjects with complete data in the analysis.  ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Classification accuracy: 0.6111 / Chance level: 0.333333\n"
          ],
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs\u003d1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs\u003d1)]: Done   7 out of   7 | elapsed:   35.3s finished\n"
          ],
          "output_type": "stream"
        },
        {
          "data": {
            "text/plain": "0.6442673314698698"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 24
        }
      ],
      "source": "# fitting on all four subjects\nlin_svc1 \u003d LinearSVC()\nallSubs_svc \u003d Pipeline([(\u0027anova\u0027, feature_selection), (\u0027svc\u0027, lin_svc1)])\nallSubs_svc.set_params(anova__percentile \u003d 2.9, svc__max_iter \u003d 5000)\nallSubs_svc.fit(X_all, Y_all)\nmodelAccuracy(allSubs_svc, X_all, Y_all, session_all)\ncross_validation \u003d cross_val_score(allSubs_svc, X_all, Y_all, cv \u003d 7, verbose \u003d 1)\ncross_validation.mean()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\u003ch5\u003eResults\u003c/h5\u003e",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": " - **DNN**  \n   Model test loss: 5.15, test accuracy: 0.4052  \n   This is only a little better than chance. I think one of the reasons may be due to the NiftiMasker transformed arrays having (324 * 39912) shapes. The 39912 dimension is probably too large for a simple DNN to handle well\n - **CNN**  \n   Model test loss: 10.24, test accuracy: 0.3649  \n   This model is only performing slightly better than chance. Compared to the last DNN model, it has disproportionally large test loss. I wonder if this is related to the shape of the fMRI data - the shape of the image is 40 * 64 * 64 for each trial, which is 3D. This dataset probably requires a Conv3D network build.\n - **Linear SVC with single subject**  \n   Model accuracy: 0.6605, cross-validation: 0.7500  \n   The accuracy is not in the 90% percentile, but it is significantly better than chance, indicating that the model is actually picking out patterns. It is only 4% lower than the [0.7037](https://nilearn.github.io/auto_examples/02_decoding/plot_haxby_anova_svm.html) accuracy the binary model achieved. \n - **Linear SVC with 4 subjects**  \n   Model accuracy: 0.6111, cross-validation: 0.6443  \n   This accuracy is lower than the model trained and tested on one subject, probably being hinged by idiosyncracies among the subjects. It is still significantly higher than pure chance, which means that there exist significant commonalities in how our brains activate in response to different visual stimuli. \n\nAn example anatomical brain scan from the dataset:\n![title](anatomical_subj2.png)\n\nAn example functional MRI brain scan:\n![title](functional_subj2.png)\n\nReverse-plotting the SVM learned weights on brain regions:\nDistinguishing faces vs cats:\n![title](faceCat.png)\nDistinguishing faces vs houses:\n![title](faceHouse.png)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\u003ch5\u003eImplications\u003c/h5\u003e\nFirstly, this project uses a public datasets of fMRI data with no identifiable personal information.    \nI became interested in this project because it is very cool that machine-learning algorithms have this potential in analysing our brains. Neural networks were inspired by the biological layout of neurons, they may very well be able to help humans learn more about the biology of our brains. Other ML algorithms such as SVM show promise as well.    \nApplying ML algorithmic analyses to brain imaging data really goes to emphasize the side of our brains that are predictable / computational. One of my classmates mentioned that projects in this area could make it possible to \"read your mind\". If that really becomes a tangible reality to predict what someone\u0027s experiencing mentally, there will be a lot of ethical implications. We will need to consider how we can protect our privacy and the personal integrity of our thought.    \nOn the other hand, ML and particularly CNN have positive implications for the medical field. Particularly the area in diagnosis of neurological disorders can benefit from use of ML. Another area that professional projects can impact is brain-computer interfaces, where researchers are already trying to decode brain activations and control prosthetics for the bettermenf of life quality for disabled people. The area that we struggle at: finding hidden connections and patterns in brain-scans, is an area of strength for AI algorithms, and we can use them to better understand how brain activation patterns indicate neurological sickness or translate to limb movements. In these areas, we can use ML methods to advance our current knowledge and improve people\u0027s well-being. \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": " ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}