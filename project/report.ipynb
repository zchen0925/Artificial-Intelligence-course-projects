{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "\u003ch4\u003e\u003ccenter\u003e AI Project Proposal Draft 2 \u003c/h4\u003e\n\u003ch5\u003eZiqi Chen\u003cbr\u003e\nCS 344\u003cbr\u003e\nMay 3rd, 2019\u003c/h5\u003e\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\u003ch5\u003eVision — Give an overview of the project and its purpose.\u003c/h6\u003e\nThis project was inspired from the neuroscience principle that our visual cortex is a complex system that designates specialized area or group of areas for the processing of different types of visual stimuli. Based on this idea, the activation patterns in our brains should be unique when we are seeing different classes of visual stimuli, such as a human face versus a cat versus an inanimate object.  \nWith the recent advance of neuroimaging technologies, we have more tools to shed light upon how our brain works. The brain scan data is piling up, but it isn\u0027t always easy for humans to pick apart the patterns and connections hidden in the fMRI images right away.  \nIn this project, I am interested to learn how to apply the strengths of Machine-Learning models we\u0027ve learned about in class: pattern-extraction, to simple analysis of neuroimagine data. This project trains ML models on a classification task, one that uses a form of represented fMRI data to find hidden distinct brain activation patterns that result from seeing a class of visual stimuli, and predicts the type of stimuli the person was seeing when this brain activity was recorded. \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\u003ch5\u003eBackground\u003c/h6\u003e\nThis project aims to do a multiclass (3) classification of brain imaging samples. I\u0027m using the [Haxby et al (2001) dataset](https://zenodo.org/record/1203329#.XNpTO0MpBqs) to perform a 3-way classification, trying to train the models to distinguish the fMRI brain scans that result from seeing a face, a cat, or a house. The dataset contains block-design fMRI data for 6 subjects who viewed 12 runs of repeated visual presentations of various stimuli. For the purpose of this project, only subjects 1 - 4 were included as they have complete fMRI data and the corresponding text labels, describing the stimuli type used in each trial. \nIn terms of fMRI data manipulation, This project relies on NiLearn, a Python Scikit-Learn based library with high-level functions for manipulation and analysis of neuroimaging data. In particular, I reference the [documentation on the NiftiMasker class](http://nilearn.github.io/modules/generated/nilearn.input_data.NiftiMasker.html) which does the heavy-lifting of readying the fMRI data to be used by models. It applies a mask to 4D fMRI images to extract 2D arrays, with each datapoint representing voxel of brain region activation * time. In loadingData.py, I cited [this NiLearn example](http://nilearn.github.io/auto_examples/plot_decoding_tutorial.html#sphx-glr-auto-examples-plot-decoding-tutorial-py) to create a data matrix from the fMRIs.\nIn terms of technologies used, I experimented with a simple [DNN](https://github.com/kvlinden-courses/cs344-code/blob/master/u08features/keras-mnist.ipynb) and [CNN](https://github.com/kvlinden-courses/cs344-code/blob/master/u09classification/keras-cnn.ipynb) models. Neural networks, especially Convolutional Neural Networks, are known for image-processing and classification, hence the inclusion in this project.  \nLast but not least, I used Linear Support Vector Machines as one of the models. Support Vector Machines are a class of supervised machine learning methods for classification and regression tasks. SVMs represent the training data as points in space (cited from [https://en.wikipedia.org/wiki/Support-vector_machine], and use a subset of training points in the decision function, also called support vectors. Its basic philosophy is to find the hyper-plane that most efficiently separates each class of samples from each other (cited from [https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/].  \nFrom talking with Professor Vander Linden during the walkthrough, I learned that Support Vector Machines have been studied for a couple decades, and they have strong support for smaller datasets. Considering the size of this dataset, SVMs seem a good choice. Additionally, Support Vector Classification is known for its strength in classification problems that have high dimensional X inputs (cited from [https://scikit-learn.org/stable/modules/svm.html]), and that is the case in this project. It is effective not only in binary classification, but also multiclass classification problems. For the latter, SVMs supports two types of approaches: one-vs-rest or one-vs-one. One-vs-rest establishes one class and compares it against the other, whereas one-vs-one compares every class with every other, hence more computationally demanding (cited from [https://stats.stackexchange.com/questions/142325/svm-three-way-classification]. This project uses the former approach, one-vs-rest. The implementation of this model is based on [https://scikit-learn.org/stable/modules/svm.html#multi-class-classification].  \nThe fine-tuning of SVM hyperparameters came from documentation on the set__params method from [this page](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\u003ch5\u003eImplementation — Summarize your implementation and, if appropriate, how it extends on the work you’ve referenced\u003c/h6\u003e\nGiven NiLearn\u0027s high-level pre-built functions, some of the implementation details will be carried out automatically in \nthe library.\nAfter reading tutorials, I think that the first step in implementation is downloading the dataset which will then be loaded\ninto Python. Next, I\u0027ll use NiLearn functions transforming 3D images with a time series into 2D arrays that Scikit accepts.\nThen a Support Vector Machine estimator will be trained on the data for the first two tasks. The parameters will be tweaked\nto achieve a satisfiable accuracy. Then, I\u0027ll need to research NiLearn functions that will plot the resulting brain activities\nfrom the prediction result arrays. Finally, for the third task, a correlation matrix need to be created based on time series data.\nA GraphicLasso estimator will be fit on the correlation matrix. I will look for existing projects on functional connectivity maps\nand compare the model\u0027s prediction with their findings. ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\u003ch5\u003eResults — Give the results of your system and comparing them with other similar work\u003c/h6\u003e\nPreliminary results will include three groups: \n1. encoding results of brain activity prediction from a task, \n2. decoding results of prediction of the task type from brain activation patterns, \n3. extrapolated functional connectivity map.\nI am still reading documentations and need to find a way to display model\u0027s accuracy for the first two tasks, and then I will\ncompare its accuracy to similar work. \nFor the third task on mapping functional connectivity, I will need to research more previous literature and compare\nthe similarity between what the estimate is and what has been discovered.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\u003ch5\u003eImplications — Discuss the social and ethical implications of using the technologies you’ve chosen for your project\u003c/h6\u003e\nThis project will be using public datasets of fMRI data.\nIn addition, my hope is to learn about how statistical models can offer leverage to analysis of activity and connection \npatterns in the brain. Maching learning technologies are good at pattern-finding and navigating multi-demensional datasets \nIt can bring  benefits to researchers of the brain who are interested in understanding normal versus abnormal patterns of activity. \nRecently, there has been a surge of interest in using fMRI brain scans as a window to understand how our brain functions \nin a healthy or diminished way. The challenge for humans in detecting useful connections is an area of strength for \nmachine learning algorithms, specifically for neural networks and statistical models that are used in the NiLearn library.\nTherefore, I think these technologies will provide researchers with more insight into the underlying workings of our brain behind the mass of fMRI data. \nIn the future, our understanding of neurological disorders such as Alzheimer\u0027s may stand to benefit from bringing machine learning\ninto the lab to assist the human medical experts. \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": " ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}